# arxiv_summarizer.py ‚Äî v0.5: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç (—Ä–∞–±–æ—Ç–∞–µ—Ç –í–ï–ó–î–ï)
from dotenv import load_dotenv
load_dotenv()  # ‚Üê —ç—Ç–∞ —Å—Ç—Ä–æ–∫–∞ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env
import arxiv
import time
import random
import json
import os
import subprocess
import sys
import requests
from datetime import datetime
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn

console = Console()

# =============== –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è: —Ü–µ–ø–æ—á–∫–∞ –ø–æ–ø—ã—Ç–æ–∫ ===============
def summarize_paper(text: str) -> str:
    """–°—É–º–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç ‚Äî –ø—Ä–æ–±—É–µ—Ç phi3 ‚Üí Groq ‚Üí fallback."""
    
    # –ü–æ–ø—ã—Ç–∫–∞ 1: phi3 (–ª–æ–∫–∞–ª—å–Ω–æ)
    phi3_summary = _try_phi3(text)
    if phi3_summary:
        return f"[phi3] {phi3_summary}"
    
    # –ü–æ–ø—ã—Ç–∫–∞ 2: Groq (–æ–±–ª–∞–∫–æ, –±–µ—Å–ø–ª–∞—Ç–Ω–æ)
    groq_summary = _try_groq(text)
    if groq_summary:
        return f"[Groq] {groq_summary}"
    
    # –ü–æ–ø—ã—Ç–∫–∞ 3: fallback (–±–µ–∑ –ò–ò)
    return f"[basic] {_fallback_summary(text)}"

def _try_phi3(text: str, max_chars: int = 800) -> str | None:
    try:
        import ollama
        input_text = text[:max_chars] + ("..." if len(text) > max_chars else "")
        prompt = f"""Summarize in 2 sentences. Focus on goal & result. Plain language.

Abstract:
{input_text}

Summary:"""
        
        with Progress(SpinnerColumn(), TextColumn("{task.description}"), transient=True) as progress:
            task = progress.add_task("üß† phi3...", total=None)
            response = ollama.generate(
                model="phi3",
                prompt=prompt,
                options={"temperature": 0.3}
            )
        summary = response["response"].strip()
        if summary.lower().startswith(("summary:", "answer:", "here")):
            summary = summary.split(":", 1)[-1].strip()
        return summary if summary and len(summary) > 20 else None
    except:
        return None

def _try_groq(text: str) -> str | None:
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        return None
    try:
        resp = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers={"Authorization": f"Bearer {api_key}"},
            json={
                "model": "llama3-8b-8192",
                "messages": [{"role": "user", "content": f"2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {text[:1000]}"}],
                "temperature": 0.3
            },
            timeout=8
        )
        if resp.status_code == 200:
            out = resp.json()["choices"][0]["message"]["content"].strip()
            return out if len(out) > 20 else None
    except:
        pass
    return None

def _fallback_summary(text: str) -> str:
    clean = text.replace('\n', ' ').strip()
    sentences = [s.strip() for s in clean.split('.') if s.strip()]
    short = '. '.join(sentences[:2]) + ('.' if len(sentences) > 2 else '')
    return short[:350] + "‚Ä¶" if len(short) > 350 else short

# =============== arXiv –ø–æ–∏—Å–∫ ===============
def search_arxiv(query: str, max_results: int = 3):
    console.print(f"üîç –ò—â—É –Ω–∞ arXiv: [bold]{query}[/bold]...")
    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.SubmittedDate)
    client = arxiv.Client(page_size=10, delay_seconds=1.5, num_retries=2)
    try:
        return list(client.results(search))[:max_results]
    except:
        return []

# =============== –í—ã–≤–æ–¥ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ===============
def display_results(results):
    if not results:
        console.print("[yellow]üì≠ –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.[/yellow]")
        return
    table = Table(title="üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã", show_lines=True)
    table.add_column("‚Ññ", style="cyan", justify="right", width=2)
    table.add_column("–ó–∞–≥–æ–ª–æ–≤–æ–∫", style="magenta", overflow="fold")
    table.add_column("–ö—Ä–∞—Ç–∫–æ", style="blue", overflow="fold")
    for i, p in enumerate(results, 1):
        short = getattr(p, 'short_summary', '...')
        table.add_row(str(i), p.title[:60], short[:70] + "..." if len(short) > 70 else short)
    console.print(table)

def save_to_markdown(results, filename="papers.md"):
    with open(filename, "w", encoding="utf-8") as f:
        f.write("# üìö –ù–∞—É—á–Ω—ã–µ –Ω–∞—Ö–æ–¥–∫–∏\n\n")
        if not results:
            f.write("> –ü—É—Å—Ç–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.\n")
            return
        for i, p in enumerate(results, 1):
            f.write(f"## {i}. {p.title}\n")
            f.write(f"- **–ê–≤—Ç–æ—Ä—ã**: {', '.join(a.name for a in p.authors)}\n")
            f.write(f"- **–î–∞—Ç–∞**: {p.published.date()}\n")
            f.write(f"- **–°—Å—ã–ª–∫–∞**: [arXiv]({p.entry_id}) | [PDF]({p.pdf_url})\n")
            f.write(f"\n### üß† –ö—Ä–∞—Ç–∫–æ:\n> {p.short_summary}\n\n")
            f.write(f"### üìù –û—Ä–∏–≥–∏–Ω–∞–ª:\n> {p.summary[:400]}{'...' if len(p.summary) > 400 else ''}\n\n")
    console.print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: [green]{filename}[/green]")

def save_to_json(results, filename="papers.json"):
    data = [{
        "title": p.title,
        "authors": [a.name for a in p.authors],
        "published": p.published.isoformat(),
        "entry_id": p.entry_id,
        "pdf_url": p.pdf_url,
        "summary_original": p.summary.replace('\n',' ').strip(),
        "summary_ai": p.short_summary
    } for p in results]
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    console.print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: [cyan]{filename}[/cyan]")

# =============== –ó–∞–ø—É—Å–∫ ===============
if __name__ == "__main__":
    console.print(Panel.fit(
        "[bold blue]ü§ñ –ù–∞—É—á–Ω—ã–π –ê–≥–µ–Ω—Ç v0.5\n"
        "–†–∞–±–æ—Ç–∞–µ—Ç –í–ï–ó–î–ï: —Å Ollama, —Å Groq –∏–ª–∏ –±–µ–∑ –ò–ò[/bold blue]\n"
        "[dim]üí° –°–æ–≤–µ—Ç: —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama –¥–ª—è –ª—É—á—à–µ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ ‚Üí https://ollama.com[/dim]",
        title="üöÄ –ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!",
        border_style="blue"
    ))

    query = input("üîç –¢–µ–º–∞ (–Ω–∞–ø—Ä. 'LLM agents'): ").strip()
    if not query:
        query = "AI for open science"

    console.rule(f"–ü–æ–∏—Å–∫: {query}")
    results = search_arxiv(query, max_results=2)

    if results:
        console.print("üß† –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è...")
        for i, paper in enumerate(results, 1):
            console.print(f"  {i}/{len(results)}")
            paper.short_summary = summarize_paper(paper.summary)
    else:
        console.print("[yellow]‚Üí –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é.[/yellow]")

    display_results(results)
    save_to_markdown(results)

    if results and input("\nüíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ JSON? (y/n): ").lower() in "y–¥":
        save_to_json(results)

    console.print("\nüéâ –ì–æ—Ç–æ–≤–æ!")
    console.print("  ‚Ä¢ –û—Ç–∫—Ä–æ–π—Ç–µ `papers.md` ‚Äî —Ç–∞–º –∫—Ä–∞—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã")
    console.print("  ‚Ä¢ –ß—Ç–æ–±—ã —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ: —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ GROQ_API_KEY")