# ðŸ“š ÐœÐ¾Ð¸ Ð½Ð°ÑƒÑ‡Ð½Ñ‹Ðµ Ð½Ð°Ñ…Ð¾Ð´ÐºÐ¸

## 1. Improved Pseudorandom Codes from Permuted Puzzles
- **ÐÐ²Ñ‚Ð¾Ñ€Ñ‹**: Miranda Christ, Noah Golowich, Sam Gunn, Ankur Moitra, Daniel Wichs
- **Ð”Ð°Ñ‚Ð°**: 2025-12-09
- **Ð¡ÑÑ‹Ð»ÐºÐ°**: [Ð§Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð½Ð° arXiv](http://arxiv.org/abs/2512.08918v1) | [PDF](https://arxiv.org/pdf/2512.08918v1)
- **ÐÐ½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ñ**:
  > Watermarks are an essential tool for identifying AI-generated content. Recently, Christ and Gunn (CRYPTO '24) introduced pseudorandom error-correcting codes (PRCs), which are equivalent to watermarks with strong robustness and quality guarantees. A PRC is a pseudorandom encryption scheme whose decryption algorithm tolerates a high rate of errors. Pseudorandomness ensures quality preservation of th...

## 2. Revisiting the Scaling Properties of Downstream Metrics in Large Language Model Training
- **ÐÐ²Ñ‚Ð¾Ñ€Ñ‹**: Jakub Krajewski, Amitis Shidani, Dan Busbridge, Sam Wiseman, Jason Ramapuram
- **Ð”Ð°Ñ‚Ð°**: 2025-12-09
- **Ð¡ÑÑ‹Ð»ÐºÐ°**: [Ð§Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð½Ð° arXiv](http://arxiv.org/abs/2512.08894v1) | [PDF](https://arxiv.org/pdf/2512.08894v1)
- **ÐÐ½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ñ**:
  > While scaling laws for Large Language Models (LLMs) traditionally focus on proxy metrics like pretraining loss, predicting downstream task performance has been considered unreliable. This paper challenges that view by proposing a direct framework to model the scaling of benchmark performance from the training budget. We find that for a fixed token-to-parameter ratio, a simple power law can accurat...

## 3. Toward Faithful Retrieval-Augmented Generation with Sparse Autoencoders
- **ÐÐ²Ñ‚Ð¾Ñ€Ñ‹**: Guangzhi Xiong, Zhenghao He, Bohan Liu, Sanchit Sinha, Aidong Zhang
- **Ð”Ð°Ñ‚Ð°**: 2025-12-09
- **Ð¡ÑÑ‹Ð»ÐºÐ°**: [Ð§Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð½Ð° arXiv](http://arxiv.org/abs/2512.08892v1) | [PDF](https://arxiv.org/pdf/2512.08892v1)
- **ÐÐ½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ñ**:
  > Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated d...

