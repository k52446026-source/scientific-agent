# ðŸ“š ÐœÐ¾Ð¸ Ð½Ð°ÑƒÑ‡Ð½Ñ‹Ðµ Ð½Ð°Ñ…Ð¾Ð´ÐºÐ¸

## 1. Revisiting Generalization Across Difficulty Levels: It's Not So Easy
- **ÐÐ²Ñ‚Ð¾Ñ€Ñ‹**: Yeganeh Kordi, Nihal V. Nayak, Max Zuo, Ilana Nguyen, Stephen H. Bach
- **Ð”Ð°Ñ‚Ð°**: 2025-11-26
- **Ð¡ÑÑ‹Ð»ÐºÐ°**: [Ð§Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð½Ð° arXiv](http://arxiv.org/abs/2511.21692v1) | [PDF](https://arxiv.org/pdf/2511.21692v1)
- **ÐÐ½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ñ**:
  > We investigate how well large language models (LLMs) generalize across different task difficulties, a key question for effective data curation and evaluation. Existing research is mixed regarding whether training on easier or harder data leads to better results, and whether those gains come on easier or harder test data. We address this question by conducting a systematic evaluation of LLMs' gener...

## 2. Canvas-to-Image: Compositional Image Generation with Multimodal Controls
- **ÐÐ²Ñ‚Ð¾Ñ€Ñ‹**: Yusuf Dalva, Guocheng Gordon Qian, Maya Goldenberg, Tsai-Shien Chen, Kfir Aberman, Sergey Tulyakov, Pinar Yanardag, Kuan-Chieh Jackson Wang
- **Ð”Ð°Ñ‚Ð°**: 2025-11-26
- **Ð¡ÑÑ‹Ð»ÐºÐ°**: [Ð§Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð½Ð° arXiv](http://arxiv.org/abs/2511.21691v1) | [PDF](https://arxiv.org/pdf/2511.21691v1)
- **ÐÐ½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ñ**:
  > While modern diffusion models excel at generating high-quality and diverse images, they still struggle with high-fidelity compositional and multimodal control, particularly when users simultaneously specify text prompts, subject references, spatial arrangements, pose constraints, and layout annotations. We introduce Canvas-to-Image, a unified framework that consolidates these heterogeneous control...

## 3. TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos
- **ÐÐ²Ñ‚Ð¾Ñ€Ñ‹**: Seungjae Lee, Yoonkyo Jung, Inkook Chun, Yao-Chih Lee, Zikui Cai, Hongjia Huang, Aayush Talreja, Tan Dat Dao, Yongyuan Liang, Jia-Bin Huang, Furong Huang
- **Ð”Ð°Ñ‚Ð°**: 2025-11-26
- **Ð¡ÑÑ‹Ð»ÐºÐ°**: [Ð§Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð½Ð° arXiv](http://arxiv.org/abs/2511.21690v1) | [PDF](https://arxiv.org/pdf/2511.21690v1)
- **ÐÐ½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ñ**:
  > Learning new robot tasks on new platforms and in new scenes from only a handful of demonstrations remains challenging. While videos of other embodiments - humans and different robots - are abundant, differences in embodiment, camera, and environment hinder their direct use. We address the small-data problem by introducing a unifying, symbolic representation - a compact 3D "trace-space" of scene-le...

